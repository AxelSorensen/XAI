{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model \"ConceptModel\" (image(x) -> concept(c)) could just be a pretrained resnet. It should take an image as input and output a vector of size 112 representing the concepts (binary attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConceptModel, self).__init__()\n",
    "        # Pre-trained ResNet50\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 112) #Updated last layer to 112\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid for probabilities of concept?\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part of the model \"PredictionModel\" (concepts(c) -> prediction(y)) should take the output vector from the conceptmodel in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PredictionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(112, 256)  # Concept vector as input in the first layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 200)  # Output layer for 200 bird species\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, c):\n",
    "        c = self.relu(self.fc1(c))\n",
    "        c = self.softmax(self.fc2(c))\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck model (the two combined in one module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BottleneckModel, self).__init__()\n",
    "        self.concept_model = ConceptModel()\n",
    "        self.prediction_model = PredictionModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        concepts = self.concept_model(x)\n",
    "        predictions = self.prediction_model(concepts)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert * NICE DATALOADER *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was thinking CrossEntropyLoss. Since the bottleneck model includes pre-trained components we might want to use different learning rates for different parts of the model? but I think it is maybe possible with PyTorch optimizers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BottleneckModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader: # placeholder (\"train_loader\")\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02463",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
